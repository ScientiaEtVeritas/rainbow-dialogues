{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokenizer Version 1.1', 'Language: en', 'Number of threads: 1']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!perl ../OpenNMT-py/tools/tokenizer.perl  -l en \\\n",
    "< ../data/\"cornell movie-dialogs corpus\"/src_movie_lines.txt \\\n",
    "> ../data/\"cornell movie-dialogs corpus\"/src_movie_lines_tok.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokenizer Version 1.1', 'Language: en', 'Number of threads: 1']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!perl ../OpenNMT-py/tools/tokenizer.perl  -l en \\\n",
    "< ../data/\"cornell movie-dialogs corpus\"/tgt_movie_lines.txt \\\n",
    "> ../data/\"cornell movie-dialogs corpus\"/tgt_movie_lines_tok.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Please backup existing pt files: ../data/cornell_raw.train*.pt, to avoid overwriting them!']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!python ../OpenNMT-py/preprocess.py --train_src \"../data/cornell movie-dialogs corpus/src_movie_lines_tok.txt\" --train_tgt \"../data/cornell movie-dialogs corpus/tgt_movie_lines_tok.txt\" --save_data ../data/cornell_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Please backup existing pt files: ../data/cornell_raw_min_30_10_tok.train*.pt, to avoid overwriting them!']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!python ../OpenNMT-py/preprocess.py --train_src \"../data/cornell movie-dialogs corpus/src_movie_lines_tok.txt\" --train_tgt \"../data/cornell movie-dialogs corpus/tgt_movie_lines_tok.txt\" --save_data ../data/cornell_raw_min_30_10_tok --src_words_min_frequency 30 --tgt_words_min_frequency 30 --src_seq_length 10 --tgt_seq_length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[2019-09-12 02:53:40,588 INFO] Extracting features...',\n",
       " '[2019-09-12 02:53:40,590 INFO]  * number of source features: 0.',\n",
       " '[2019-09-12 02:53:40,591 INFO]  * number of target features: 0.',\n",
       " '[2019-09-12 02:53:40,591 INFO] Building `Fields` object...',\n",
       " '[2019-09-12 02:53:40,591 INFO] Building & saving training data...',\n",
       " '[2019-09-12 02:53:40,591 INFO] Reading source and target files: ../data/cornell movie-dialogs corpus/src_movie_lines_tok.txt ../data/cornell movie-dialogs corpus/tgt_movie_lines_tok.txt.',\n",
       " '[2019-09-12 02:53:40,770 INFO] Building shard 0.',\n",
       " '[2019-09-12 02:53:48,692 INFO]  * saving 0th train data shard to ../data/cornell_raw_min_100_tok.train.0.pt.',\n",
       " '[2019-09-12 02:53:49,922 INFO]  * tgt vocab size: 379.',\n",
       " '[2019-09-12 02:53:49,948 INFO]  * src vocab size: 380.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!python ../OpenNMT-py/preprocess.py --train_src \"../data/cornell movie-dialogs corpus/src_movie_lines_tok.txt\" --train_tgt \"../data/cornell movie-dialogs corpus/tgt_movie_lines_tok.txt\" --save_data ../data/cornell_raw_min_100_tok --src_words_min_frequency 100 --tgt_words_min_frequency 100 --src_seq_length 10 --tgt_seq_length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_fields = torch.load(\"../data/cornell_raw_min_100_tok.vocab.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text_field = vocab_fields[\"src\"].base_field\n",
    "src_vocab = src_text_field.vocab\n",
    "src_padding = src_vocab.stoi[src_text_field.pad_token] #stoi: mapping token strings to numerical identifiers.\n",
    "# ['<unk>', '<blank>', 'I', 'you', 'the', 'to', 'a', 'of', 'and', 'You']\n",
    "# src_text_field.pad_token : '<blank>'\n",
    "\n",
    "tgt_text_field = vocab_fields['tgt'].base_field\n",
    "tgt_vocab = tgt_text_field.vocab\n",
    "tgt_padding = tgt_vocab.stoi[tgt_text_field.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.src_vocab_size = len(src_vocab)\n",
    "config.tgt_vocab_size = len(tgt_vocab)\n",
    "config.src_padding = src_padding\n",
    "config.tgt_padding = tgt_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.src_unk = src_vocab.stoi[src_text_field.unk_token]\n",
    "config.tgt_unk = tgt_vocab.stoi[tgt_text_field.unk_token]\n",
    "config.tgt_bos = tgt_vocab.stoi[tgt_text_field.init_token]\n",
    "config.tgt_eos = tgt_vocab.stoi[tgt_text_field.eos_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.src_vocab = src_vocab\n",
    "config.tgt_vocab = tgt_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading dataset from ../data/cornell_raw_min_100_tok.train.0.pt\n",
      "INFO:root:number of examples: 72114\n"
     ]
    }
   ],
   "source": [
    "import onmt\n",
    "from itertools import chain\n",
    "\n",
    "train_data_file = \"../data/cornell_raw_min_100_tok.train.0.pt\"\n",
    "train_iter = onmt.inputters.inputter.DatasetLazyIter(dataset_paths=[train_data_file],\n",
    "                                                     fields=vocab_fields,\n",
    "                                                     batch_size=1,\n",
    "                                                     batch_size_multiple=1,\n",
    "                                                     batch_size_fn=None,\n",
    "                                                     device=\"cpu\",\n",
    "                                                     is_train=True,\n",
    "                                                     repeat=False,\n",
    "                                                     pool_factor=8192)\n",
    "\n",
    "data = list(train_iter)\n",
    "filtered_data = []\n",
    "for x in data:\n",
    "    # Filtering sentences with <unk> token\n",
    "    if not ((x.src[0].squeeze() == config.src_unk).any() or (x.tgt.squeeze() == config.tgt_unk).any()):\n",
    "        filtered_data.append(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.PRELOADING_SIZE = len(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Stats"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### 8,216 records"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### 380 src vocabulary size"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### 379 tgt vocabulary size"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f'#### Stats'))\n",
    "display(Markdown(f'##### {config.PRELOADING_SIZE:,} records'))\n",
    "display(Markdown(f'##### {config.src_vocab_size:,} src vocabulary size'))\n",
    "display(Markdown(f'##### {config.tgt_vocab_size:,} tgt vocabulary size'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq-DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run modules/NoisyLinear.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run modules/DQN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run modules/Model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(config, DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (encoder_embeddings): Embeddings(\n",
       "    (make_embedding): Sequential(\n",
       "      (emb_luts): Elementwise(\n",
       "        (0): Embedding(380, 100, padding_idx=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): RNNEncoder(\n",
       "    (embeddings): Embeddings(\n",
       "      (make_embedding): Sequential(\n",
       "        (emb_luts): Elementwise(\n",
       "          (0): Embedding(380, 100, padding_idx=1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rnn): LSTM(100, 250, bidirectional=True)\n",
       "  )\n",
       "  (decoder_embeddings): Embeddings(\n",
       "    (make_embedding): Sequential(\n",
       "      (emb_luts): Elementwise(\n",
       "        (0): Embedding(379, 100, padding_idx=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): InputFeedRNNDecoder(\n",
       "    (embeddings): Embeddings(\n",
       "      (make_embedding): Sequential(\n",
       "        (emb_luts): Elementwise(\n",
       "          (0): Embedding(379, 100, padding_idx=1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0)\n",
       "    (rnn): StackedLSTM(\n",
       "      (dropout): Dropout(p=0.0)\n",
       "      (layers): ModuleList(\n",
       "        (0): LSTMCell(600, 500)\n",
       "      )\n",
       "    )\n",
       "    (attn): GlobalAttention(\n",
       "      (linear_in): Linear(in_features=500, out_features=500, bias=False)\n",
       "      (linear_out): Linear(in_features=1000, out_features=500, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (advantages): Sequential(\n",
       "      (0): NoisyLinear()\n",
       "      (1): ReLU()\n",
       "      (2): NoisyLinear()\n",
       "    )\n",
       "    (value): Sequential(\n",
       "      (0): NoisyLinear()\n",
       "      (1): ReLU()\n",
       "      (2): NoisyLinear()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.current_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run modules/MSELoss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MSELoss(\n",
    "    #nn.MSELoss(reduction=\"none\"),\n",
    "    nn.SmoothL1Loss(reduction=\"none\"),\n",
    "    model.current_model.generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run modules/Reward.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.rewards = ['BLEU']\n",
    "config.rewards_weights = [1]    \n",
    "\n",
    "reward = Reward(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1\n",
    "torch_optimizer = torch.optim.SGD(model.current_model.parameters(), lr=lr)\n",
    "optim = onmt.utils.optimizers.Optimizer(torch_optimizer, learning_rate=lr, max_grad_norm=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#report_manager = onmt.utils.ReportMgr(report_every=1, start_time=None, tensorboard_writer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preload Experience Replay Buffer\n",
    "if len(model.replay_memory) == 0:\n",
    "    for example in filtered_data:\n",
    "        model.replay_memory.preload(example.src[0].squeeze(1), example.tgt.squeeze(1), 1)\n",
    "        model.sample_buffer.preload(example.src[0].squeeze(1), example.tgt.squeeze(1), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run modules/QLearning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = QLearning(config,\n",
    "                    model,\n",
    "                    reward=reward,\n",
    "                    train_loss=loss,\n",
    "                    valid_loss=loss,\n",
    "                    optim=optim,\n",
    "                    gpu_verbose_level=100)\n",
    "                    #shard_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in model.target_model.parameters():\n",
    "#    print(i.abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes sir .  ||  <s> Are you sure ? </s>\n",
      "I can &apos;t tell you .  ||  <s> Where we going ? </s>\n",
      "So you did fuck up .  ||  <s> Yes . </s>\n",
      "What do you mean ?  ||  <s> What &apos;s it like where I &apos;m going ? </s>\n",
      "No .  ||  <s> But why not ? </s>\n",
      "Do you believe in it ?  ||  <s> What ? </s>\n",
      "Well ?  ||  <s> Well what ? </s>\n",
      "Hello .  ||  <s> Hi . </s>\n",
      "Where is she ?  ||  <s> With her mother . </s>\n",
      "And now ?  ||  <s> And now I want you . </s>\n"
     ]
    }
   ],
   "source": [
    "#for i, t in enumerate(model.replay_memory._storage):\n",
    "#    if t[1].size(0) > 10:\n",
    "#        print(i, t[1].size(0), t[1])\n",
    "    \n",
    "    #if t[1][-1].item() == 96:\n",
    "    #    print(i, t[1][-1])\n",
    "    #    print(t[1].size())\n",
    "    #print((t[1] == 0).sum())\n",
    "    #print(t[1].size(0))\n",
    "    \n",
    "#for x in model.replay_memory._storage:\n",
    "#    #print([t for t in x[1]])\n",
    "#    print(' '.join([tgt_vocab.itos[t.item()] for t in x[1]]))\n",
    "\n",
    "for i, x in enumerate(filtered_data[5000:5010]):\n",
    "    print(' '.join([src_vocab.itos[token] for token in x.src[0].squeeze().tolist()]) + '  ||  ' + ' '.join([tgt_vocab.itos[token] for token in x.tgt.squeeze().tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.train(train_steps=100000, valid_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 25],\n",
       "         [  7],\n",
       "         [ 98],\n",
       "         [515],\n",
       "         [912],\n",
       "         [ 73],\n",
       "         [ 71],\n",
       "         [  2]]), tensor([[419],\n",
       "         [419],\n",
       "         [419],\n",
       "         [419],\n",
       "         [419],\n",
       "         [419],\n",
       "         [419],\n",
       "         [419],\n",
       "         [419],\n",
       "         [419],\n",
       "         [419],\n",
       "         [419]]), tensor(0.0765))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.replay_memory._storage[30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in model.replay_memory._storage[190000:190020]:\n",
    "#    print(' '.join([src_vocab.itos[token] for token in x[0].squeeze().tolist()]) + '  ||  ' + ' '.join([tgt_vocab.itos[token] for token in x[1].squeeze().tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000 1000\n",
      "1000 2000 1000\n",
      "2000 3000 1000\n",
      "3000 4000 1000\n",
      "4000 5000 1000\n",
      "5000 6000 1000\n",
      "6000 7000 1000\n",
      "7000 8000 1000\n",
      "8000 9000 tensor(269.1369)\n",
      "9000 10000 tensor(69.9702)\n",
      "10000 11000 tensor(68.1051)\n",
      "11000 12000 tensor(70.0445)\n",
      "12000 13000 tensor(69.2290)\n",
      "13000 14000 tensor(67.6353)\n",
      "14000 15000 tensor(69.1051)\n",
      "15000 16000 tensor(69.9398)\n",
      "16000 17000 tensor(67.1464)\n",
      "17000 18000 tensor(40.8107)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(model.replay_memory),1000):\n",
    "    print(i, i+1000, sum([y[2] for y in model.replay_memory._storage[i:i+1000]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000 2865.5386549279237\n",
      "1000 2000 2854.8148937806864\n",
      "2000 3000 2921.720928437504\n",
      "3000 4000 2842.947141045659\n",
      "4000 5000 2923.080664388974\n",
      "5000 6000 2846.373647637572\n",
      "6000 7000 2857.5506537195292\n",
      "7000 8000 2906.641666827157\n",
      "8000 9000 5019.612149560479\n",
      "9000 10000 6265.274101594786\n",
      "10000 11000 7026.173323113606\n",
      "11000 12000 7777.136460404011\n",
      "12000 13000 8890.74375323773\n",
      "13000 14000 9831.411941575092\n",
      "14000 15000 11290.923115782087\n",
      "15000 16000 12465.047093196603\n",
      "16000 17000 13669.182292303707\n",
      "17000 18000 8865.997057539264\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(model.replay_memory),1000):\n",
    "    print(i, i+1000, sum([model.replay_memory._it_sum[y] for y in range(i, i+1000)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n",
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n",
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n",
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n",
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n",
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n",
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n",
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n",
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n",
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n",
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n",
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n",
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n",
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n",
      "[[tensor([293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293])]]\n"
     ]
    }
   ],
   "source": [
    "for x in model.replay_memory._storage[5:20]:\n",
    "    #print(\"SRC\", x[0])\n",
    "    #print(\"TGT\", x[1].unsqueeze(0))\n",
    "    text = model.current_model.infer(x[0].unsqueeze(1), torch.ShortTensor([x[0].size(0)]), 1)\n",
    "    print(text)\n",
    "    text = [[torch.LongTensor([3])]]\n",
    "    #print(type(text), type(text[0]), type(text[0][0]))\n",
    "    #print(\"Prediction:\",  torch.cat((torch.LongTensor([config.tgt_bos]), text[0][0])))\n",
    "    #print(' '.join([src_vocab.itos[token] for token in x[0].squeeze().tolist()]) + '  ||  ' + ' '.join([tgt_vocab.itos[token] for token in text[0][0].tolist()]))\n",
    "    #print(reward(x[0], [[torch.cat((torch.LongTensor([config.tgt_bos]), text[0][0]))]], x[1].unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
